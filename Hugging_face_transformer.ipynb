{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6eaa23-8683-4b60-b392-12fde7ba70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ishikaupadhyay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ishikaupadhyay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function for multilingual support\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Load and combine datasets\n",
    "data1 = pd.read_csv('/Users/ishikaupadhyay/Desktop/advanced phishing detection/dataset_phishing.csv')\n",
    "data2 = pd.read_csv('/Users/ishikaupadhyay/Desktop/advanced phishing detection/emails.csv')\n",
    "data3 = pd.read_csv('/Users/ishikaupadhyay/Desktop/advanced phishing detection/phishing_Legitimate_full.csv')\n",
    "\n",
    "combined_data = pd.concat([data1, data2, data3], ignore_index=True)\n",
    "\n",
    "# Check and clean missing values\n",
    "combined_data['message'] = combined_data['message'].fillna('')\n",
    "combined_data['url'] = combined_data['url'].fillna('')\n",
    "combined_data['status'] = combined_data['status'].fillna('unknown')\n",
    "\n",
    "# Prepare inputs and labels\n",
    "combined_data['text'] = combined_data.apply(\n",
    "    lambda row: f\"Email: {preprocess_text(row['message'])} URL: {row['url']}\",\n",
    "    axis=1\n",
    ")\n",
    "combined_data['label'] = combined_data['status'].replace({'legitimate': 0, 'phishing': 1})\n",
    "\n",
    "# Filter unknown statuses if any\n",
    "combined_data = combined_data[combined_data['label'].isin([0, 1])]\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(combined_data[['text', 'label']], test_size=0.2, random_state=42, stratify=combined_data['label'])\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"test\": Dataset.from_pandas(test_df),\n",
    "})\n",
    "\n",
    "# Tokenizer and model setup (smaller multilingual model)\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,  \n",
    "    per_device_train_batch_size=16, \n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"Starting model training...\")\n",
    "trainer.train()\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./distilbert_phishing_model\")\n",
    "tokenizer.save_pretrained(\"./distilbert_phishing_model\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1 Score: {test_results['eval_f1']:.4f}\")\n",
    "\n",
    "# Predictions for the confusion matrix\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predicted_labels = predictions.predictions.argmax(-1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Legitimate\", \"Phishing\"], yticklabels=[\"Legitimate\", \"Phishing\"])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Prediction function with multilingual support\n",
    "def classify_email(email, url, threshold=0.5):\n",
    "    input_text = f\"Email: {preprocess_text(email)} URL: {url}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256).to(model.device)\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "    phishing_probability = probabilities[0][1].item()\n",
    "    return \"Phishing\" if phishing_probability > threshold else \"Legitimate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f92f1-41df-4a2d-99fc-9e34fdac4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = {\n",
    "    \"English\": [\n",
    "        {\"email\": \"Dear customer, your order has been shipped.\", \"url\": \"https://www.legitstore.com/track\"},\n",
    "        {\"email\": \"Urgent: Account suspended. Verify now!\", \"url\": \"http://phishing-scam.com/login\"},\n",
    "    ],\n",
    "    \"Spanish\": [\n",
    "        {\"email\": \"Estimado cliente, su pedido ha sido enviado.\", \"url\": \"https://www.tiendalegitima.es/rastreo\"},\n",
    "        {\"email\": \"¡Alerta! Su cuenta está bloqueada. Verifique ahora.\", \"url\": \"http://phishing-estafa.es/login\"},\n",
    "    ],\n",
    "    \"German\": [\n",
    "        {\"email\": \"Sehr geehrter Kunde, Ihre Bestellung wurde versandt.\", \"url\": \"https://www.echterladen.de/verfolgung\"},\n",
    "        {\"email\": \"Achtung: Ihr Konto wurde gesperrt. Jetzt verifizieren!\", \"url\": \"http://phishing-betrug.de/einloggen\"},\n",
    "    ],\n",
    "    \"French\": [\n",
    "        {\"email\": \"Urgent : Compte suspendu. Vérifiez maintenant !\", \"url\": \"http://phishing-arnaque.fr/login\"},\n",
    "    ],\n",
    "    \"Italian\": [\n",
    "        {\"email\": \"Urgente: Account sospeso. Verifica ora!\", \"url\": \"http://phishing-truffa.it/accesso\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "for language, emails in examples.items():\n",
    "    print(f\"Testing {language} examples:\")\n",
    "    for example in emails:\n",
    "        email = example[\"email\"]\n",
    "        url = example[\"url\"]\n",
    "        result = classify_email(email, url)\n",
    "        print(f\"Email: {email}\\nURL: {url}\\nResult: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab40e9-14e4-4a8a-a56e-88fb99953508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
